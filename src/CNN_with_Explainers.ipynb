{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN with Explainers",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKju90nnzcf_",
        "colab_type": "text"
      },
      "source": [
        "# Running CNN with Explainers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17Cu-aIPKvrt",
        "colab_type": "text"
      },
      "source": [
        "This file contains the pipeline for training and loading the CNN model and generating explanations for the model.\n",
        "\n",
        "This model operates on Tensorflow 1.15 and Keras. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0Bpr0FZKxvi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c82d649-7f8b-44c5-9767-24b189366de4"
      },
      "source": [
        "!pip install innvestigate\n",
        "!pip install aix360\n",
        "!pip install lime\n",
        "!pip install Pillow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: innvestigate in /usr/local/lib/python3.6/dist-packages (1.0.8)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from innvestigate) (5.4.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from innvestigate) (3.6.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from innvestigate) (1.18.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from innvestigate) (2.10.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from innvestigate) (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from innvestigate) (1.4.1)\n",
            "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (from innvestigate) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->innvestigate) (47.1.1)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->innvestigate) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->innvestigate) (1.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->innvestigate) (1.12.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->innvestigate) (19.3.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->innvestigate) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->innvestigate) (8.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->innvestigate) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->innvestigate) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->innvestigate) (1.1.2)\n",
            "Requirement already satisfied: aix360 in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: bleach>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from aix360) (3.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from aix360) (2.23.0)\n",
            "Requirement already satisfied: lime in /usr/local/lib/python3.6/dist-packages (from aix360) (0.2.0.0)\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.6/dist-packages (from aix360) (1.0.31)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.6/dist-packages (from aix360) (1.2.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from aix360) (1.5.0+cu101)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from aix360) (0.15.1)\n",
            "Requirement already satisfied: Image in /usr/local/lib/python3.6/dist-packages (from aix360) (1.5.32)\n",
            "Requirement already satisfied: tensorflow==1.14 in /usr/local/lib/python3.6/dist-packages (from aix360) (1.14.0)\n",
            "Requirement already satisfied: Pygments in /usr/local/lib/python3.6/dist-packages (from aix360) (2.1.3)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.6/dist-packages (from aix360) (0.35.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from aix360) (2.2.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from aix360) (0.16.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from aix360) (1.18.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.6/dist-packages (from aix360) (0.22.2.post1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from aix360) (0.6.0+cu101)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from aix360) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from aix360) (3.2.1)\n",
            "Requirement already satisfied: docutils>=0.13.1 in /usr/local/lib/python3.6/dist-packages (from aix360) (0.15.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (from aix360) (0.90)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from aix360) (1.0.4)\n",
            "Requirement already satisfied: xport in /usr/local/lib/python3.6/dist-packages (from aix360) (2.0.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bleach>=2.1.0->aix360) (1.12.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach>=2.1.0->aix360) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach>=2.1.0->aix360) (20.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->aix360) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->aix360) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->aix360) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->aix360) (2020.4.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from lime->aix360) (4.41.1)\n",
            "Requirement already satisfied: pillow==5.4.1 in /usr/local/lib/python3.6/dist-packages (from lime->aix360) (5.4.1)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from cvxpy->aix360) (0.6.1)\n",
            "Requirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.6/dist-packages (from cvxpy->aix360) (2.1.2)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.6/dist-packages (from cvxpy->aix360) (2.0.7.post1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from cvxpy->aix360) (0.70.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->aix360) (0.16.0)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.6/dist-packages (from Image->aix360) (3.0.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14->aix360) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14->aix360) (0.34.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14->aix360) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14->aix360) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14->aix360) (0.9.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14->aix360) (0.3.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14->aix360) (1.29.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14->aix360) (3.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14->aix360) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14->aix360) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14->aix360) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14->aix360) (1.12.1)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14->aix360) (1.14.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->aix360) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->aix360) (2.10.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->aix360) (2.4)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->aix360) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->aix360) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aix360) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aix360) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aix360) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aix360) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->aix360) (2018.9)\n",
            "Requirement already satisfied: dill>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from multiprocess->cvxpy->aix360) (0.3.1.1)\n",
            "Requirement already satisfied: asgiref~=3.2 in /usr/local/lib/python3.6/dist-packages (from django->Image->aix360) (3.2.7)\n",
            "Requirement already satisfied: sqlparse>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from django->Image->aix360) (0.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14->aix360) (47.1.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (1.0.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->aix360) (4.4.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (3.1.0)\n",
            "Requirement already satisfied: lime in /usr/local/lib/python3.6/dist-packages (0.2.0.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.6/dist-packages (from lime) (0.16.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from lime) (0.22.2.post1)\n",
            "Requirement already satisfied: pillow==5.4.1 in /usr/local/lib/python3.6/dist-packages (from lime) (5.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lime) (1.18.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from lime) (3.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from lime) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lime) (1.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->lime) (0.15.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.4.7)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->lime) (1.12.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (5.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzoKAeUk5zcX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "71580b32-a584-415e-fc72-515258791104"
      },
      "source": [
        "%tensorflow_version 1.15\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.15`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu1yyo2ZzgOF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2ef13cd3-ff37-4c66-95c4-00cc5b07d9fc"
      },
      "source": [
        "import os\n",
        "import cnn_kuzushiji\n",
        "import experiment"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPSTXNnK2h2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_tf = True\n",
        "if use_tf:\n",
        "    import tensorflow.keras as keras\n",
        "else:\n",
        "    import keras\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jrXETy5zlqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6dc33fed-9229-4761-e98c-086ddf95b35f"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qLqRMbNWUlZ",
        "colab_type": "text"
      },
      "source": [
        "# Train CNN Model\n",
        "We train the CNN model using the Kuzushiji-49 dataset. Trained models for epochs are saved in `/report/` as .h5 files. \n",
        "\n",
        "To run inference without training, change parameter `train_model = False` in `cnn_kuzushiji.experiment()`. In the dictionary `cnn_params`, add in the location of the model file to load as a value of `load_location`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe2lHeHk14_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d5ed2d66-aa17-478a-f38a-d304f65fd987"
      },
      "source": [
        " #   check GPU\n",
        "if tf.test.gpu_device_name():\n",
        "    print(\"Default GPU Device: {}\".format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"No GPU.\")\n",
        "\n",
        "num_epochs = 300\n",
        "batch_size = 256\n",
        "\n",
        "dl_params = {\n",
        "        'labels':           ['a', 'me'],\n",
        "        'label_type':       'int',\n",
        "        'presorted':        True,\n",
        "        'file_locs':        [\"./data/kuzushiji-49/0\", \"./data/kuzushiji-49/33\"],\n",
        "        'file_exten':       '.png',\n",
        "        #'set_ratio':        [0.7, 0.15, 0.15],\n",
        "        'set_ratio':        [0.8, 0.2],\n",
        "        'batch_size':       batch_size,\n",
        "        'target_size':      (28,28),\n",
        "        'balanced':         True,\n",
        "        'grayscale':        True,\n",
        "        'superspeedmode':   False                #   trades off memory efficiency for less computation (USE AT YOUR OWN RISK)\n",
        "}\n",
        "\n",
        "train_params = {\n",
        "        'learning_rate':        0.0075,\n",
        "        'learning_decay':       0.9,\n",
        "        'num_epochs':           num_epochs,\n",
        "        'batch_size':           batch_size,\n",
        "        'save_n_epoch':         10,\n",
        "        'loss_fcn':             'binary_crossentropy',\n",
        "        'report_metrics':       ['accuracy'],\n",
        "        'plot_filename':        'training_plot',\n",
        "        'test_filename':        'test_report',\n",
        "        'report_dir':           './report/',\n",
        "        }\n",
        "\n",
        "\n",
        "img_height, img_width, img_channels = (28, 28, 3)\n",
        "num_classes = 1             #   use 1 if binary\n",
        "\n",
        "cnn_params = {\n",
        "        'input_size':           (img_height, img_width, img_channels),\n",
        "        'num_filters':          3,\n",
        "        'filter_size':          (5, 5),\n",
        "        'stride':               1,\n",
        "        'padding':              'same',\n",
        "        'conv_activation':      'relu',\n",
        "        'pool_size':            (2,2),\n",
        "        'dropout':              0.1,\n",
        "        'num_conv_layers':      2,\n",
        "        'output_dim':           num_classes,\n",
        "        'fc_activation':        'sigmoid',\n",
        "        'load_location':        '',\n",
        "        'report_metrics':       ['accuracy'],\n",
        "        }"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-bqRkEGznLZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5721147a-1242-4a3e-928e-a401b5015a62"
      },
      "source": [
        "cnn_kuzushiji.experiment(dl_params, cnn_params, train_params, train_model=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/cnn_kuzushiji.py:46: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/cnn_kuzushiji.py:47: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/cnn_kuzushiji.py:48: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
            "\n",
            "Saving parameters...\n",
            "Loading data...\n",
            "Loading data from ./data/kuzushiji-49/0 ...\n",
            "Getting samples for class 0...\n",
            "There are 2715 training, 678validation, 552 test samples.\n",
            "Loading data from ./data/kuzushiji-49/33 ...\n",
            "Getting samples for class 1...\n",
            "There are 2715 training, 678validation, 552 test samples.\n",
            "There are 5430 training samples and 22 training batches.\n",
            "There are 1356 validation samples and 6 validation batches.\n",
            "There are 1104 test samples and 5 test batches.\n",
            "Converting from grayscale to RGB...\n",
            "Building classifier...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 28, 28, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 3)         228       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 3)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 3)         12        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 3)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 3)         228       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 14, 14, 3)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 3)         12        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 3)           0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 7, 7, 3)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 147)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 148       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 628\n",
            "Trainable params: 616\n",
            "Non-trainable params: 12\n",
            "_________________________________________________________________\n",
            "Training classifier...\n",
            "Learning rate:  0.0075\n",
            "Learning decay:  0.9\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 5430 samples, validate on 1356 samples\n",
            "Epoch 1/300\n",
            " - 6s - loss: 1.0009 - acc: 0.5304 - val_loss: 0.8054 - val_acc: 0.5796\n",
            "Epoch 2/300\n",
            " - 5s - loss: 0.7632 - acc: 0.5991 - val_loss: 0.7132 - val_acc: 0.6364\n",
            "Epoch 3/300\n",
            " - 5s - loss: 0.7022 - acc: 0.6354 - val_loss: 0.6661 - val_acc: 0.6490\n",
            "Epoch 4/300\n",
            " - 5s - loss: 0.6726 - acc: 0.6567 - val_loss: 0.6379 - val_acc: 0.6615\n",
            "Epoch 5/300\n",
            " - 5s - loss: 0.6533 - acc: 0.6608 - val_loss: 0.6175 - val_acc: 0.6785\n",
            "Epoch 6/300\n",
            " - 5s - loss: 0.6250 - acc: 0.6777 - val_loss: 0.6021 - val_acc: 0.6903\n",
            "Epoch 7/300\n",
            " - 5s - loss: 0.6283 - acc: 0.6827 - val_loss: 0.5895 - val_acc: 0.7028\n",
            "Epoch 8/300\n",
            " - 5s - loss: 0.6133 - acc: 0.6781 - val_loss: 0.5786 - val_acc: 0.7094\n",
            "Epoch 9/300\n",
            " - 5s - loss: 0.6046 - acc: 0.6873 - val_loss: 0.5697 - val_acc: 0.7146\n",
            "Epoch 10/300\n",
            " - 5s - loss: 0.5985 - acc: 0.6856 - val_loss: 0.5615 - val_acc: 0.7190\n",
            "Model saved for epoch  9 10\n",
            "Epoch 11/300\n",
            " - 5s - loss: 0.5790 - acc: 0.7081 - val_loss: 0.5546 - val_acc: 0.7227\n",
            "Epoch 12/300\n",
            " - 5s - loss: 0.5787 - acc: 0.7099 - val_loss: 0.5487 - val_acc: 0.7249\n",
            "Epoch 13/300\n",
            " - 5s - loss: 0.5666 - acc: 0.7144 - val_loss: 0.5429 - val_acc: 0.7271\n",
            "Epoch 14/300\n",
            " - 5s - loss: 0.5659 - acc: 0.7145 - val_loss: 0.5374 - val_acc: 0.7330\n",
            "Epoch 15/300\n",
            " - 5s - loss: 0.5455 - acc: 0.7278 - val_loss: 0.5326 - val_acc: 0.7367\n",
            "Epoch 16/300\n",
            " - 5s - loss: 0.5586 - acc: 0.7201 - val_loss: 0.5286 - val_acc: 0.7375\n",
            "Epoch 17/300\n",
            " - 5s - loss: 0.5607 - acc: 0.7166 - val_loss: 0.5248 - val_acc: 0.7397\n",
            "Epoch 18/300\n",
            " - 5s - loss: 0.5452 - acc: 0.7258 - val_loss: 0.5212 - val_acc: 0.7419\n",
            "Epoch 19/300\n",
            " - 5s - loss: 0.5455 - acc: 0.7306 - val_loss: 0.5176 - val_acc: 0.7448\n",
            "Epoch 20/300\n",
            " - 5s - loss: 0.5478 - acc: 0.7274 - val_loss: 0.5144 - val_acc: 0.7463\n",
            "Model saved for epoch  19 10\n",
            "Epoch 21/300\n",
            " - 5s - loss: 0.5375 - acc: 0.7385 - val_loss: 0.5114 - val_acc: 0.7471\n",
            "Epoch 22/300\n",
            " - 5s - loss: 0.5258 - acc: 0.7372 - val_loss: 0.5084 - val_acc: 0.7478\n",
            "Epoch 23/300\n",
            " - 5s - loss: 0.5371 - acc: 0.7333 - val_loss: 0.5058 - val_acc: 0.7493\n",
            "Epoch 24/300\n",
            " - 5s - loss: 0.5256 - acc: 0.7409 - val_loss: 0.5031 - val_acc: 0.7537\n",
            "Epoch 25/300\n",
            " - 5s - loss: 0.5300 - acc: 0.7420 - val_loss: 0.5007 - val_acc: 0.7559\n",
            "Epoch 26/300\n",
            " - 5s - loss: 0.5224 - acc: 0.7429 - val_loss: 0.4984 - val_acc: 0.7544\n",
            "Epoch 27/300\n",
            " - 5s - loss: 0.5134 - acc: 0.7517 - val_loss: 0.4961 - val_acc: 0.7566\n",
            "Epoch 28/300\n",
            " - 5s - loss: 0.5180 - acc: 0.7479 - val_loss: 0.4938 - val_acc: 0.7588\n",
            "Epoch 29/300\n",
            " - 5s - loss: 0.5240 - acc: 0.7389 - val_loss: 0.4917 - val_acc: 0.7611\n",
            "Epoch 30/300\n",
            " - 5s - loss: 0.5136 - acc: 0.7530 - val_loss: 0.4898 - val_acc: 0.7611\n",
            "Model saved for epoch  29 10\n",
            "Epoch 31/300\n",
            " - 5s - loss: 0.5069 - acc: 0.7565 - val_loss: 0.4880 - val_acc: 0.7625\n",
            "Epoch 32/300\n",
            " - 5s - loss: 0.5064 - acc: 0.7552 - val_loss: 0.4862 - val_acc: 0.7640\n",
            "Epoch 33/300\n",
            " - 5s - loss: 0.5060 - acc: 0.7560 - val_loss: 0.4844 - val_acc: 0.7655\n",
            "Epoch 34/300\n",
            " - 5s - loss: 0.5081 - acc: 0.7558 - val_loss: 0.4828 - val_acc: 0.7670\n",
            "Epoch 35/300\n",
            " - 5s - loss: 0.5025 - acc: 0.7580 - val_loss: 0.4813 - val_acc: 0.7670\n",
            "Epoch 36/300\n",
            " - 5s - loss: 0.5047 - acc: 0.7602 - val_loss: 0.4796 - val_acc: 0.7684\n",
            "Epoch 37/300\n",
            " - 5s - loss: 0.5023 - acc: 0.7595 - val_loss: 0.4782 - val_acc: 0.7684\n",
            "Epoch 38/300\n",
            " - 5s - loss: 0.4989 - acc: 0.7534 - val_loss: 0.4766 - val_acc: 0.7699\n",
            "Epoch 39/300\n",
            " - 5s - loss: 0.4910 - acc: 0.7650 - val_loss: 0.4751 - val_acc: 0.7714\n",
            "Epoch 40/300\n",
            " - 5s - loss: 0.4898 - acc: 0.7635 - val_loss: 0.4736 - val_acc: 0.7736\n",
            "Model saved for epoch  39 10\n",
            "Epoch 41/300\n",
            " - 5s - loss: 0.4935 - acc: 0.7630 - val_loss: 0.4724 - val_acc: 0.7743\n",
            "Epoch 42/300\n",
            " - 5s - loss: 0.4901 - acc: 0.7657 - val_loss: 0.4710 - val_acc: 0.7758\n",
            "Epoch 43/300\n",
            " - 5s - loss: 0.4926 - acc: 0.7597 - val_loss: 0.4697 - val_acc: 0.7758\n",
            "Epoch 44/300\n",
            " - 5s - loss: 0.4893 - acc: 0.7689 - val_loss: 0.4684 - val_acc: 0.7765\n",
            "Epoch 45/300\n",
            " - 5s - loss: 0.4918 - acc: 0.7611 - val_loss: 0.4672 - val_acc: 0.7780\n",
            "Epoch 46/300\n",
            " - 5s - loss: 0.4906 - acc: 0.7632 - val_loss: 0.4661 - val_acc: 0.7795\n",
            "Epoch 47/300\n",
            " - 5s - loss: 0.4820 - acc: 0.7720 - val_loss: 0.4650 - val_acc: 0.7788\n",
            "Epoch 48/300\n",
            " - 5s - loss: 0.4803 - acc: 0.7707 - val_loss: 0.4640 - val_acc: 0.7780\n",
            "Epoch 49/300\n",
            " - 5s - loss: 0.4811 - acc: 0.7656 - val_loss: 0.4629 - val_acc: 0.7788\n",
            "Epoch 50/300\n",
            " - 5s - loss: 0.4745 - acc: 0.7689 - val_loss: 0.4618 - val_acc: 0.7788\n",
            "Model saved for epoch  49 10\n",
            "Epoch 51/300\n",
            " - 5s - loss: 0.4858 - acc: 0.7691 - val_loss: 0.4607 - val_acc: 0.7810\n",
            "Epoch 52/300\n",
            " - 5s - loss: 0.4870 - acc: 0.7680 - val_loss: 0.4596 - val_acc: 0.7824\n",
            "Epoch 53/300\n",
            " - 5s - loss: 0.4881 - acc: 0.7645 - val_loss: 0.4585 - val_acc: 0.7824\n",
            "Epoch 54/300\n",
            " - 5s - loss: 0.4783 - acc: 0.7777 - val_loss: 0.4575 - val_acc: 0.7832\n",
            "Epoch 55/300\n",
            " - 5s - loss: 0.4821 - acc: 0.7729 - val_loss: 0.4565 - val_acc: 0.7832\n",
            "Epoch 56/300\n",
            " - 5s - loss: 0.4734 - acc: 0.7753 - val_loss: 0.4555 - val_acc: 0.7847\n",
            "Epoch 57/300\n",
            " - 5s - loss: 0.4763 - acc: 0.7766 - val_loss: 0.4546 - val_acc: 0.7854\n",
            "Epoch 58/300\n",
            " - 5s - loss: 0.4658 - acc: 0.7770 - val_loss: 0.4537 - val_acc: 0.7861\n",
            "Epoch 59/300\n",
            " - 5s - loss: 0.4684 - acc: 0.7762 - val_loss: 0.4528 - val_acc: 0.7869\n",
            "Epoch 60/300\n",
            " - 5s - loss: 0.4659 - acc: 0.7786 - val_loss: 0.4518 - val_acc: 0.7869\n",
            "Model saved for epoch  59 10\n",
            "Epoch 61/300\n",
            " - 5s - loss: 0.4712 - acc: 0.7766 - val_loss: 0.4509 - val_acc: 0.7876\n",
            "Epoch 62/300\n",
            " - 5s - loss: 0.4657 - acc: 0.7818 - val_loss: 0.4502 - val_acc: 0.7876\n",
            "Epoch 63/300\n",
            " - 5s - loss: 0.4685 - acc: 0.7799 - val_loss: 0.4494 - val_acc: 0.7876\n",
            "Epoch 64/300\n",
            " - 5s - loss: 0.4650 - acc: 0.7821 - val_loss: 0.4485 - val_acc: 0.7883\n",
            "Epoch 65/300\n",
            " - 5s - loss: 0.4635 - acc: 0.7805 - val_loss: 0.4477 - val_acc: 0.7876\n",
            "Epoch 66/300\n",
            " - 5s - loss: 0.4602 - acc: 0.7908 - val_loss: 0.4469 - val_acc: 0.7898\n",
            "Epoch 67/300\n",
            " - 5s - loss: 0.4658 - acc: 0.7827 - val_loss: 0.4461 - val_acc: 0.7898\n",
            "Epoch 68/300\n",
            " - 5s - loss: 0.4684 - acc: 0.7818 - val_loss: 0.4453 - val_acc: 0.7906\n",
            "Epoch 69/300\n",
            " - 5s - loss: 0.4658 - acc: 0.7838 - val_loss: 0.4446 - val_acc: 0.7928\n",
            "Epoch 70/300\n",
            " - 5s - loss: 0.4641 - acc: 0.7847 - val_loss: 0.4439 - val_acc: 0.7928\n",
            "Model saved for epoch  69 10\n",
            "Epoch 71/300\n",
            " - 5s - loss: 0.4649 - acc: 0.7825 - val_loss: 0.4432 - val_acc: 0.7928\n",
            "Epoch 72/300\n",
            " - 5s - loss: 0.4520 - acc: 0.7904 - val_loss: 0.4424 - val_acc: 0.7935\n",
            "Epoch 73/300\n",
            " - 5s - loss: 0.4687 - acc: 0.7768 - val_loss: 0.4417 - val_acc: 0.7950\n",
            "Epoch 74/300\n",
            " - 5s - loss: 0.4568 - acc: 0.7877 - val_loss: 0.4411 - val_acc: 0.7957\n",
            "Epoch 75/300\n",
            " - 5s - loss: 0.4533 - acc: 0.7937 - val_loss: 0.4405 - val_acc: 0.7965\n",
            "Epoch 76/300\n",
            " - 5s - loss: 0.4569 - acc: 0.7901 - val_loss: 0.4398 - val_acc: 0.7972\n",
            "Epoch 77/300\n",
            " - 5s - loss: 0.4537 - acc: 0.7843 - val_loss: 0.4392 - val_acc: 0.7987\n",
            "Epoch 78/300\n",
            " - 5s - loss: 0.4567 - acc: 0.7869 - val_loss: 0.4386 - val_acc: 0.7979\n",
            "Epoch 79/300\n",
            " - 5s - loss: 0.4604 - acc: 0.7869 - val_loss: 0.4379 - val_acc: 0.7987\n",
            "Epoch 80/300\n",
            " - 5s - loss: 0.4548 - acc: 0.7947 - val_loss: 0.4372 - val_acc: 0.7987\n",
            "Model saved for epoch  79 10\n",
            "Epoch 81/300\n",
            " - 5s - loss: 0.4466 - acc: 0.7934 - val_loss: 0.4366 - val_acc: 0.7994\n",
            "Epoch 82/300\n",
            " - 5s - loss: 0.4617 - acc: 0.7807 - val_loss: 0.4360 - val_acc: 0.8001\n",
            "Epoch 83/300\n",
            " - 5s - loss: 0.4572 - acc: 0.7895 - val_loss: 0.4354 - val_acc: 0.7994\n",
            "Epoch 84/300\n",
            " - 5s - loss: 0.4437 - acc: 0.7954 - val_loss: 0.4348 - val_acc: 0.8001\n",
            "Epoch 85/300\n",
            " - 5s - loss: 0.4551 - acc: 0.7888 - val_loss: 0.4342 - val_acc: 0.8001\n",
            "Epoch 86/300\n",
            " - 5s - loss: 0.4495 - acc: 0.7939 - val_loss: 0.4336 - val_acc: 0.8009\n",
            "Epoch 87/300\n",
            " - 5s - loss: 0.4526 - acc: 0.7917 - val_loss: 0.4331 - val_acc: 0.8016\n",
            "Epoch 88/300\n",
            " - 5s - loss: 0.4505 - acc: 0.7871 - val_loss: 0.4325 - val_acc: 0.8016\n",
            "Epoch 89/300\n",
            " - 5s - loss: 0.4513 - acc: 0.7926 - val_loss: 0.4319 - val_acc: 0.8016\n",
            "Epoch 90/300\n",
            " - 5s - loss: 0.4503 - acc: 0.7956 - val_loss: 0.4313 - val_acc: 0.8024\n",
            "Model saved for epoch  89 10\n",
            "Epoch 91/300\n",
            " - 5s - loss: 0.4448 - acc: 0.7947 - val_loss: 0.4308 - val_acc: 0.8031\n",
            "Epoch 92/300\n",
            " - 5s - loss: 0.4443 - acc: 0.7950 - val_loss: 0.4303 - val_acc: 0.8038\n",
            "Epoch 93/300\n",
            " - 5s - loss: 0.4451 - acc: 0.7978 - val_loss: 0.4297 - val_acc: 0.8038\n",
            "Epoch 94/300\n",
            " - 5s - loss: 0.4470 - acc: 0.7972 - val_loss: 0.4292 - val_acc: 0.8053\n",
            "Epoch 95/300\n",
            " - 5s - loss: 0.4441 - acc: 0.7958 - val_loss: 0.4287 - val_acc: 0.8053\n",
            "Epoch 96/300\n",
            " - 5s - loss: 0.4407 - acc: 0.7982 - val_loss: 0.4282 - val_acc: 0.8060\n",
            "Epoch 97/300\n",
            " - 5s - loss: 0.4393 - acc: 0.8053 - val_loss: 0.4278 - val_acc: 0.8053\n",
            "Epoch 98/300\n",
            " - 5s - loss: 0.4467 - acc: 0.7954 - val_loss: 0.4273 - val_acc: 0.8046\n",
            "Epoch 99/300\n",
            " - 5s - loss: 0.4446 - acc: 0.7978 - val_loss: 0.4269 - val_acc: 0.8046\n",
            "Epoch 100/300\n",
            " - 5s - loss: 0.4419 - acc: 0.8017 - val_loss: 0.4263 - val_acc: 0.8046\n",
            "Model saved for epoch  99 10\n",
            "Epoch 101/300\n",
            " - 5s - loss: 0.4399 - acc: 0.7969 - val_loss: 0.4259 - val_acc: 0.8053\n",
            "Epoch 102/300\n",
            " - 5s - loss: 0.4392 - acc: 0.7991 - val_loss: 0.4254 - val_acc: 0.8053\n",
            "Epoch 103/300\n",
            " - 5s - loss: 0.4411 - acc: 0.7932 - val_loss: 0.4249 - val_acc: 0.8060\n",
            "Epoch 104/300\n",
            " - 5s - loss: 0.4463 - acc: 0.7934 - val_loss: 0.4244 - val_acc: 0.8060\n",
            "Epoch 105/300\n",
            " - 5s - loss: 0.4393 - acc: 0.7967 - val_loss: 0.4239 - val_acc: 0.8060\n",
            "Epoch 106/300\n",
            " - 5s - loss: 0.4389 - acc: 0.7971 - val_loss: 0.4235 - val_acc: 0.8075\n",
            "Epoch 107/300\n",
            " - 5s - loss: 0.4429 - acc: 0.7956 - val_loss: 0.4231 - val_acc: 0.8068\n",
            "Epoch 108/300\n",
            " - 5s - loss: 0.4337 - acc: 0.8024 - val_loss: 0.4226 - val_acc: 0.8068\n",
            "Epoch 109/300\n",
            " - 5s - loss: 0.4407 - acc: 0.7967 - val_loss: 0.4221 - val_acc: 0.8068\n",
            "Epoch 110/300\n",
            " - 5s - loss: 0.4320 - acc: 0.8042 - val_loss: 0.4218 - val_acc: 0.8068\n",
            "Model saved for epoch  109 10\n",
            "Epoch 111/300\n",
            " - 5s - loss: 0.4391 - acc: 0.8024 - val_loss: 0.4213 - val_acc: 0.8075\n",
            "Epoch 112/300\n",
            " - 5s - loss: 0.4344 - acc: 0.8041 - val_loss: 0.4209 - val_acc: 0.8083\n",
            "Epoch 113/300\n",
            " - 5s - loss: 0.4390 - acc: 0.8006 - val_loss: 0.4204 - val_acc: 0.8083\n",
            "Epoch 114/300\n",
            " - 5s - loss: 0.4335 - acc: 0.8026 - val_loss: 0.4200 - val_acc: 0.8083\n",
            "Epoch 115/300\n",
            " - 5s - loss: 0.4371 - acc: 0.7974 - val_loss: 0.4196 - val_acc: 0.8097\n",
            "Epoch 116/300\n",
            " - 5s - loss: 0.4324 - acc: 0.7972 - val_loss: 0.4192 - val_acc: 0.8090\n",
            "Epoch 117/300\n",
            " - 5s - loss: 0.4344 - acc: 0.8006 - val_loss: 0.4188 - val_acc: 0.8112\n",
            "Epoch 118/300\n",
            " - 5s - loss: 0.4354 - acc: 0.8024 - val_loss: 0.4185 - val_acc: 0.8097\n",
            "Epoch 119/300\n",
            " - 5s - loss: 0.4267 - acc: 0.8088 - val_loss: 0.4181 - val_acc: 0.8105\n",
            "Epoch 120/300\n",
            " - 5s - loss: 0.4339 - acc: 0.8041 - val_loss: 0.4177 - val_acc: 0.8105\n",
            "Model saved for epoch  119 10\n",
            "Epoch 121/300\n",
            " - 5s - loss: 0.4244 - acc: 0.8088 - val_loss: 0.4173 - val_acc: 0.8112\n",
            "Epoch 122/300\n",
            " - 5s - loss: 0.4336 - acc: 0.7943 - val_loss: 0.4169 - val_acc: 0.8142\n",
            "Epoch 123/300\n",
            " - 5s - loss: 0.4284 - acc: 0.8039 - val_loss: 0.4166 - val_acc: 0.8142\n",
            "Epoch 124/300\n",
            " - 5s - loss: 0.4333 - acc: 0.8053 - val_loss: 0.4162 - val_acc: 0.8127\n",
            "Epoch 125/300\n",
            " - 5s - loss: 0.4263 - acc: 0.8048 - val_loss: 0.4159 - val_acc: 0.8127\n",
            "Epoch 126/300\n",
            " - 5s - loss: 0.4284 - acc: 0.8066 - val_loss: 0.4155 - val_acc: 0.8127\n",
            "Epoch 127/300\n",
            " - 5s - loss: 0.4275 - acc: 0.8052 - val_loss: 0.4153 - val_acc: 0.8127\n",
            "Epoch 128/300\n",
            " - 5s - loss: 0.4398 - acc: 0.7978 - val_loss: 0.4149 - val_acc: 0.8127\n",
            "Epoch 129/300\n",
            " - 5s - loss: 0.4320 - acc: 0.8068 - val_loss: 0.4145 - val_acc: 0.8119\n",
            "Epoch 130/300\n",
            " - 5s - loss: 0.4280 - acc: 0.8052 - val_loss: 0.4141 - val_acc: 0.8127\n",
            "Model saved for epoch  129 10\n",
            "Epoch 131/300\n",
            " - 5s - loss: 0.4204 - acc: 0.8083 - val_loss: 0.4138 - val_acc: 0.8119\n",
            "Epoch 132/300\n",
            " - 5s - loss: 0.4298 - acc: 0.8085 - val_loss: 0.4135 - val_acc: 0.8119\n",
            "Epoch 133/300\n",
            " - 5s - loss: 0.4305 - acc: 0.8052 - val_loss: 0.4131 - val_acc: 0.8134\n",
            "Epoch 134/300\n",
            " - 5s - loss: 0.4279 - acc: 0.8007 - val_loss: 0.4128 - val_acc: 0.8142\n",
            "Epoch 135/300\n",
            " - 5s - loss: 0.4315 - acc: 0.8002 - val_loss: 0.4124 - val_acc: 0.8142\n",
            "Epoch 136/300\n",
            " - 5s - loss: 0.4231 - acc: 0.8046 - val_loss: 0.4121 - val_acc: 0.8142\n",
            "Epoch 137/300\n",
            " - 5s - loss: 0.4228 - acc: 0.8098 - val_loss: 0.4117 - val_acc: 0.8149\n",
            "Epoch 138/300\n",
            " - 5s - loss: 0.4271 - acc: 0.8033 - val_loss: 0.4114 - val_acc: 0.8149\n",
            "Epoch 139/300\n",
            " - 5s - loss: 0.4296 - acc: 0.8017 - val_loss: 0.4111 - val_acc: 0.8149\n",
            "Epoch 140/300\n",
            " - 5s - loss: 0.4266 - acc: 0.8092 - val_loss: 0.4108 - val_acc: 0.8149\n",
            "Model saved for epoch  139 10\n",
            "Epoch 141/300\n",
            " - 5s - loss: 0.4266 - acc: 0.8072 - val_loss: 0.4105 - val_acc: 0.8149\n",
            "Epoch 142/300\n",
            " - 5s - loss: 0.4255 - acc: 0.8068 - val_loss: 0.4102 - val_acc: 0.8149\n",
            "Epoch 143/300\n",
            " - 5s - loss: 0.4308 - acc: 0.7998 - val_loss: 0.4099 - val_acc: 0.8149\n",
            "Epoch 144/300\n",
            " - 5s - loss: 0.4232 - acc: 0.8110 - val_loss: 0.4095 - val_acc: 0.8149\n",
            "Epoch 145/300\n",
            " - 5s - loss: 0.4273 - acc: 0.7994 - val_loss: 0.4092 - val_acc: 0.8149\n",
            "Epoch 146/300\n",
            " - 5s - loss: 0.4215 - acc: 0.8136 - val_loss: 0.4090 - val_acc: 0.8149\n",
            "Epoch 147/300\n",
            " - 5s - loss: 0.4200 - acc: 0.8087 - val_loss: 0.4086 - val_acc: 0.8149\n",
            "Epoch 148/300\n",
            " - 5s - loss: 0.4158 - acc: 0.8122 - val_loss: 0.4084 - val_acc: 0.8149\n",
            "Epoch 149/300\n",
            " - 5s - loss: 0.4256 - acc: 0.8068 - val_loss: 0.4081 - val_acc: 0.8156\n",
            "Epoch 150/300\n",
            " - 5s - loss: 0.4143 - acc: 0.8110 - val_loss: 0.4077 - val_acc: 0.8164\n",
            "Model saved for epoch  149 10\n",
            "Epoch 151/300\n",
            " - 5s - loss: 0.4207 - acc: 0.8122 - val_loss: 0.4075 - val_acc: 0.8164\n",
            "Epoch 152/300\n",
            " - 5s - loss: 0.4200 - acc: 0.8072 - val_loss: 0.4072 - val_acc: 0.8164\n",
            "Epoch 153/300\n",
            " - 5s - loss: 0.4208 - acc: 0.8112 - val_loss: 0.4069 - val_acc: 0.8164\n",
            "Epoch 154/300\n",
            " - 5s - loss: 0.4210 - acc: 0.8088 - val_loss: 0.4066 - val_acc: 0.8171\n",
            "Epoch 155/300\n",
            " - 5s - loss: 0.4217 - acc: 0.8125 - val_loss: 0.4063 - val_acc: 0.8178\n",
            "Epoch 156/300\n",
            " - 5s - loss: 0.4211 - acc: 0.8031 - val_loss: 0.4061 - val_acc: 0.8178\n",
            "Epoch 157/300\n",
            " - 5s - loss: 0.4121 - acc: 0.8162 - val_loss: 0.4058 - val_acc: 0.8186\n",
            "Epoch 158/300\n",
            " - 5s - loss: 0.4127 - acc: 0.8184 - val_loss: 0.4055 - val_acc: 0.8186\n",
            "Epoch 159/300\n",
            " - 5s - loss: 0.4165 - acc: 0.8110 - val_loss: 0.4052 - val_acc: 0.8186\n",
            "Epoch 160/300\n",
            " - 5s - loss: 0.4146 - acc: 0.8155 - val_loss: 0.4049 - val_acc: 0.8193\n",
            "Model saved for epoch  159 10\n",
            "Epoch 161/300\n",
            " - 5s - loss: 0.4127 - acc: 0.8116 - val_loss: 0.4047 - val_acc: 0.8193\n",
            "Epoch 162/300\n",
            " - 5s - loss: 0.4178 - acc: 0.8101 - val_loss: 0.4044 - val_acc: 0.8201\n",
            "Epoch 163/300\n",
            " - 5s - loss: 0.4203 - acc: 0.8029 - val_loss: 0.4041 - val_acc: 0.8208\n",
            "Epoch 164/300\n",
            " - 5s - loss: 0.4193 - acc: 0.8092 - val_loss: 0.4039 - val_acc: 0.8208\n",
            "Epoch 165/300\n",
            " - 5s - loss: 0.4206 - acc: 0.8090 - val_loss: 0.4036 - val_acc: 0.8201\n",
            "Epoch 166/300\n",
            " - 5s - loss: 0.4182 - acc: 0.8098 - val_loss: 0.4034 - val_acc: 0.8201\n",
            "Epoch 167/300\n",
            " - 5s - loss: 0.4172 - acc: 0.8092 - val_loss: 0.4031 - val_acc: 0.8201\n",
            "Epoch 168/300\n",
            " - 5s - loss: 0.4207 - acc: 0.8083 - val_loss: 0.4028 - val_acc: 0.8208\n",
            "Epoch 169/300\n",
            " - 5s - loss: 0.4167 - acc: 0.8149 - val_loss: 0.4026 - val_acc: 0.8215\n",
            "Epoch 170/300\n",
            " - 5s - loss: 0.4156 - acc: 0.8131 - val_loss: 0.4023 - val_acc: 0.8208\n",
            "Model saved for epoch  169 10\n",
            "Epoch 171/300\n",
            " - 5s - loss: 0.4184 - acc: 0.8112 - val_loss: 0.4021 - val_acc: 0.8208\n",
            "Epoch 172/300\n",
            " - 5s - loss: 0.4154 - acc: 0.8157 - val_loss: 0.4018 - val_acc: 0.8208\n",
            "Epoch 173/300\n",
            " - 5s - loss: 0.4174 - acc: 0.8114 - val_loss: 0.4015 - val_acc: 0.8208\n",
            "Epoch 174/300\n",
            " - 5s - loss: 0.4142 - acc: 0.8138 - val_loss: 0.4013 - val_acc: 0.8208\n",
            "Epoch 175/300\n",
            " - 5s - loss: 0.4179 - acc: 0.8087 - val_loss: 0.4011 - val_acc: 0.8208\n",
            "Epoch 176/300\n",
            " - 5s - loss: 0.4119 - acc: 0.8134 - val_loss: 0.4009 - val_acc: 0.8208\n",
            "Epoch 177/300\n",
            " - 5s - loss: 0.4135 - acc: 0.8169 - val_loss: 0.4006 - val_acc: 0.8208\n",
            "Epoch 178/300\n",
            " - 5s - loss: 0.4110 - acc: 0.8186 - val_loss: 0.4004 - val_acc: 0.8208\n",
            "Epoch 179/300\n",
            " - 5s - loss: 0.4197 - acc: 0.8147 - val_loss: 0.4001 - val_acc: 0.8208\n",
            "Epoch 180/300\n",
            " - 5s - loss: 0.4181 - acc: 0.8151 - val_loss: 0.3999 - val_acc: 0.8208\n",
            "Model saved for epoch  179 10\n",
            "Epoch 181/300\n",
            " - 5s - loss: 0.4181 - acc: 0.8168 - val_loss: 0.3997 - val_acc: 0.8215\n",
            "Epoch 182/300\n",
            " - 5s - loss: 0.4171 - acc: 0.8142 - val_loss: 0.3994 - val_acc: 0.8215\n",
            "Epoch 183/300\n",
            " - 5s - loss: 0.4156 - acc: 0.8127 - val_loss: 0.3992 - val_acc: 0.8215\n",
            "Epoch 184/300\n",
            " - 5s - loss: 0.4119 - acc: 0.8151 - val_loss: 0.3990 - val_acc: 0.8215\n",
            "Epoch 185/300\n",
            " - 5s - loss: 0.4113 - acc: 0.8122 - val_loss: 0.3987 - val_acc: 0.8215\n",
            "Epoch 186/300\n",
            " - 5s - loss: 0.4093 - acc: 0.8230 - val_loss: 0.3985 - val_acc: 0.8223\n",
            "Epoch 187/300\n",
            " - 5s - loss: 0.4209 - acc: 0.8085 - val_loss: 0.3983 - val_acc: 0.8223\n",
            "Epoch 188/300\n",
            " - 5s - loss: 0.4106 - acc: 0.8175 - val_loss: 0.3981 - val_acc: 0.8237\n",
            "Epoch 189/300\n",
            " - 5s - loss: 0.4064 - acc: 0.8188 - val_loss: 0.3979 - val_acc: 0.8237\n",
            "Epoch 190/300\n",
            " - 5s - loss: 0.4020 - acc: 0.8228 - val_loss: 0.3976 - val_acc: 0.8245\n",
            "Model saved for epoch  189 10\n",
            "Epoch 191/300\n",
            " - 5s - loss: 0.4084 - acc: 0.8190 - val_loss: 0.3974 - val_acc: 0.8245\n",
            "Epoch 192/300\n",
            " - 5s - loss: 0.4101 - acc: 0.8210 - val_loss: 0.3972 - val_acc: 0.8245\n",
            "Epoch 193/300\n",
            " - 5s - loss: 0.4063 - acc: 0.8250 - val_loss: 0.3970 - val_acc: 0.8245\n",
            "Epoch 194/300\n",
            " - 5s - loss: 0.4083 - acc: 0.8210 - val_loss: 0.3968 - val_acc: 0.8252\n",
            "Epoch 195/300\n",
            " - 5s - loss: 0.4091 - acc: 0.8162 - val_loss: 0.3966 - val_acc: 0.8245\n",
            "Epoch 196/300\n",
            " - 5s - loss: 0.4143 - acc: 0.8164 - val_loss: 0.3964 - val_acc: 0.8252\n",
            "Epoch 197/300\n",
            " - 5s - loss: 0.4076 - acc: 0.8204 - val_loss: 0.3961 - val_acc: 0.8252\n",
            "Epoch 198/300\n",
            " - 5s - loss: 0.4086 - acc: 0.8166 - val_loss: 0.3959 - val_acc: 0.8252\n",
            "Epoch 199/300\n",
            " - 5s - loss: 0.4047 - acc: 0.8227 - val_loss: 0.3957 - val_acc: 0.8252\n",
            "Epoch 200/300\n",
            " - 5s - loss: 0.4045 - acc: 0.8197 - val_loss: 0.3955 - val_acc: 0.8252\n",
            "Model saved for epoch  199 10\n",
            "Epoch 201/300\n",
            " - 5s - loss: 0.3971 - acc: 0.8263 - val_loss: 0.3953 - val_acc: 0.8252\n",
            "Epoch 202/300\n",
            " - 5s - loss: 0.4094 - acc: 0.8168 - val_loss: 0.3951 - val_acc: 0.8252\n",
            "Epoch 203/300\n",
            " - 5s - loss: 0.4060 - acc: 0.8234 - val_loss: 0.3949 - val_acc: 0.8252\n",
            "Epoch 204/300\n",
            " - 5s - loss: 0.4134 - acc: 0.8142 - val_loss: 0.3947 - val_acc: 0.8252\n",
            "Epoch 205/300\n",
            " - 5s - loss: 0.4100 - acc: 0.8192 - val_loss: 0.3945 - val_acc: 0.8245\n",
            "Epoch 206/300\n",
            " - 5s - loss: 0.4032 - acc: 0.8225 - val_loss: 0.3942 - val_acc: 0.8245\n",
            "Epoch 207/300\n",
            " - 5s - loss: 0.4080 - acc: 0.8171 - val_loss: 0.3940 - val_acc: 0.8245\n",
            "Epoch 208/300\n",
            " - 5s - loss: 0.4074 - acc: 0.8203 - val_loss: 0.3938 - val_acc: 0.8245\n",
            "Epoch 209/300\n",
            " - 5s - loss: 0.4026 - acc: 0.8223 - val_loss: 0.3937 - val_acc: 0.8260\n",
            "Epoch 210/300\n",
            " - 5s - loss: 0.4056 - acc: 0.8145 - val_loss: 0.3935 - val_acc: 0.8260\n",
            "Model saved for epoch  209 10\n",
            "Epoch 211/300\n",
            " - 5s - loss: 0.4066 - acc: 0.8260 - val_loss: 0.3933 - val_acc: 0.8260\n",
            "Epoch 212/300\n",
            " - 5s - loss: 0.4078 - acc: 0.8177 - val_loss: 0.3930 - val_acc: 0.8252\n",
            "Epoch 213/300\n",
            " - 5s - loss: 0.3987 - acc: 0.8158 - val_loss: 0.3929 - val_acc: 0.8260\n",
            "Epoch 214/300\n",
            " - 5s - loss: 0.4052 - acc: 0.8188 - val_loss: 0.3927 - val_acc: 0.8252\n",
            "Epoch 215/300\n",
            " - 5s - loss: 0.4024 - acc: 0.8179 - val_loss: 0.3925 - val_acc: 0.8252\n",
            "Epoch 216/300\n",
            " - 5s - loss: 0.4015 - acc: 0.8227 - val_loss: 0.3923 - val_acc: 0.8252\n",
            "Epoch 217/300\n",
            " - 5s - loss: 0.4056 - acc: 0.8140 - val_loss: 0.3921 - val_acc: 0.8260\n",
            "Epoch 218/300\n",
            " - 5s - loss: 0.4043 - acc: 0.8203 - val_loss: 0.3919 - val_acc: 0.8260\n",
            "Epoch 219/300\n",
            " - 5s - loss: 0.4038 - acc: 0.8186 - val_loss: 0.3917 - val_acc: 0.8260\n",
            "Epoch 220/300\n",
            " - 5s - loss: 0.3969 - acc: 0.8219 - val_loss: 0.3916 - val_acc: 0.8260\n",
            "Model saved for epoch  219 10\n",
            "Epoch 221/300\n",
            " - 5s - loss: 0.4042 - acc: 0.8195 - val_loss: 0.3914 - val_acc: 0.8260\n",
            "Epoch 222/300\n",
            " - 5s - loss: 0.4053 - acc: 0.8197 - val_loss: 0.3912 - val_acc: 0.8260\n",
            "Epoch 223/300\n",
            " - 5s - loss: 0.3957 - acc: 0.8243 - val_loss: 0.3910 - val_acc: 0.8267\n",
            "Epoch 224/300\n",
            " - 5s - loss: 0.4074 - acc: 0.8186 - val_loss: 0.3908 - val_acc: 0.8260\n",
            "Epoch 225/300\n",
            " - 5s - loss: 0.4033 - acc: 0.8193 - val_loss: 0.3906 - val_acc: 0.8260\n",
            "Epoch 226/300\n",
            " - 5s - loss: 0.3988 - acc: 0.8225 - val_loss: 0.3905 - val_acc: 0.8267\n",
            "Epoch 227/300\n",
            " - 5s - loss: 0.3976 - acc: 0.8287 - val_loss: 0.3903 - val_acc: 0.8260\n",
            "Epoch 228/300\n",
            " - 5s - loss: 0.4067 - acc: 0.8177 - val_loss: 0.3901 - val_acc: 0.8267\n",
            "Epoch 229/300\n",
            " - 5s - loss: 0.4039 - acc: 0.8180 - val_loss: 0.3899 - val_acc: 0.8267\n",
            "Epoch 230/300\n",
            " - 5s - loss: 0.4104 - acc: 0.8145 - val_loss: 0.3897 - val_acc: 0.8267\n",
            "Model saved for epoch  229 10\n",
            "Epoch 231/300\n",
            " - 5s - loss: 0.4069 - acc: 0.8158 - val_loss: 0.3896 - val_acc: 0.8274\n",
            "Epoch 232/300\n",
            " - 5s - loss: 0.4005 - acc: 0.8206 - val_loss: 0.3895 - val_acc: 0.8274\n",
            "Epoch 233/300\n",
            " - 5s - loss: 0.4054 - acc: 0.8214 - val_loss: 0.3892 - val_acc: 0.8267\n",
            "Epoch 234/300\n",
            " - 5s - loss: 0.4041 - acc: 0.8138 - val_loss: 0.3891 - val_acc: 0.8267\n",
            "Epoch 235/300\n",
            " - 5s - loss: 0.4036 - acc: 0.8201 - val_loss: 0.3889 - val_acc: 0.8267\n",
            "Epoch 236/300\n",
            " - 5s - loss: 0.4032 - acc: 0.8197 - val_loss: 0.3888 - val_acc: 0.8274\n",
            "Epoch 237/300\n",
            " - 5s - loss: 0.4057 - acc: 0.8151 - val_loss: 0.3886 - val_acc: 0.8282\n",
            "Epoch 238/300\n",
            " - 5s - loss: 0.3955 - acc: 0.8276 - val_loss: 0.3884 - val_acc: 0.8282\n",
            "Epoch 239/300\n",
            " - 5s - loss: 0.4042 - acc: 0.8234 - val_loss: 0.3883 - val_acc: 0.8282\n",
            "Epoch 240/300\n",
            " - 5s - loss: 0.3935 - acc: 0.8285 - val_loss: 0.3882 - val_acc: 0.8282\n",
            "Model saved for epoch  239 10\n",
            "Epoch 241/300\n",
            " - 5s - loss: 0.4019 - acc: 0.8184 - val_loss: 0.3880 - val_acc: 0.8282\n",
            "Epoch 242/300\n",
            " - 5s - loss: 0.4021 - acc: 0.8175 - val_loss: 0.3878 - val_acc: 0.8282\n",
            "Epoch 243/300\n",
            " - 5s - loss: 0.3938 - acc: 0.8245 - val_loss: 0.3876 - val_acc: 0.8289\n",
            "Epoch 244/300\n",
            " - 5s - loss: 0.3962 - acc: 0.8227 - val_loss: 0.3875 - val_acc: 0.8289\n",
            "Epoch 245/300\n",
            " - 5s - loss: 0.3966 - acc: 0.8256 - val_loss: 0.3873 - val_acc: 0.8289\n",
            "Epoch 246/300\n",
            " - 5s - loss: 0.4016 - acc: 0.8284 - val_loss: 0.3871 - val_acc: 0.8289\n",
            "Epoch 247/300\n",
            " - 5s - loss: 0.4040 - acc: 0.8155 - val_loss: 0.3869 - val_acc: 0.8289\n",
            "Epoch 248/300\n",
            " - 5s - loss: 0.4006 - acc: 0.8221 - val_loss: 0.3868 - val_acc: 0.8289\n",
            "Epoch 249/300\n",
            " - 5s - loss: 0.3981 - acc: 0.8228 - val_loss: 0.3866 - val_acc: 0.8289\n",
            "Epoch 250/300\n",
            " - 5s - loss: 0.3936 - acc: 0.8263 - val_loss: 0.3865 - val_acc: 0.8289\n",
            "Model saved for epoch  249 10\n",
            "Epoch 251/300\n",
            " - 5s - loss: 0.4067 - acc: 0.8158 - val_loss: 0.3863 - val_acc: 0.8289\n",
            "Epoch 252/300\n",
            " - 5s - loss: 0.3979 - acc: 0.8232 - val_loss: 0.3862 - val_acc: 0.8289\n",
            "Epoch 253/300\n",
            " - 5s - loss: 0.3953 - acc: 0.8192 - val_loss: 0.3860 - val_acc: 0.8289\n",
            "Epoch 254/300\n",
            " - 5s - loss: 0.4030 - acc: 0.8199 - val_loss: 0.3858 - val_acc: 0.8289\n",
            "Epoch 255/300\n",
            " - 5s - loss: 0.3994 - acc: 0.8214 - val_loss: 0.3857 - val_acc: 0.8289\n",
            "Epoch 256/300\n",
            " - 5s - loss: 0.3923 - acc: 0.8306 - val_loss: 0.3856 - val_acc: 0.8296\n",
            "Epoch 257/300\n",
            " - 5s - loss: 0.3980 - acc: 0.8223 - val_loss: 0.3854 - val_acc: 0.8296\n",
            "Epoch 258/300\n",
            " - 5s - loss: 0.3920 - acc: 0.8278 - val_loss: 0.3853 - val_acc: 0.8296\n",
            "Epoch 259/300\n",
            " - 5s - loss: 0.3970 - acc: 0.8169 - val_loss: 0.3851 - val_acc: 0.8296\n",
            "Epoch 260/300\n",
            " - 5s - loss: 0.4010 - acc: 0.8221 - val_loss: 0.3850 - val_acc: 0.8296\n",
            "Model saved for epoch  259 10\n",
            "Epoch 261/300\n",
            " - 5s - loss: 0.4007 - acc: 0.8184 - val_loss: 0.3848 - val_acc: 0.8296\n",
            "Epoch 262/300\n",
            " - 5s - loss: 0.4020 - acc: 0.8219 - val_loss: 0.3847 - val_acc: 0.8296\n",
            "Epoch 263/300\n",
            " - 5s - loss: 0.3983 - acc: 0.8243 - val_loss: 0.3845 - val_acc: 0.8296\n",
            "Epoch 264/300\n",
            " - 5s - loss: 0.3945 - acc: 0.8250 - val_loss: 0.3844 - val_acc: 0.8296\n",
            "Epoch 265/300\n",
            " - 5s - loss: 0.3931 - acc: 0.8285 - val_loss: 0.3842 - val_acc: 0.8296\n",
            "Epoch 266/300\n",
            " - 5s - loss: 0.3928 - acc: 0.8252 - val_loss: 0.3841 - val_acc: 0.8296\n",
            "Epoch 267/300\n",
            " - 5s - loss: 0.3937 - acc: 0.8285 - val_loss: 0.3839 - val_acc: 0.8296\n",
            "Epoch 268/300\n",
            " - 5s - loss: 0.3927 - acc: 0.8273 - val_loss: 0.3838 - val_acc: 0.8296\n",
            "Epoch 269/300\n",
            " - 5s - loss: 0.3965 - acc: 0.8247 - val_loss: 0.3836 - val_acc: 0.8296\n",
            "Epoch 270/300\n",
            " - 5s - loss: 0.3944 - acc: 0.8280 - val_loss: 0.3835 - val_acc: 0.8296\n",
            "Model saved for epoch  269 10\n",
            "Epoch 271/300\n",
            " - 5s - loss: 0.3893 - acc: 0.8284 - val_loss: 0.3833 - val_acc: 0.8296\n",
            "Epoch 272/300\n",
            " - 5s - loss: 0.3902 - acc: 0.8256 - val_loss: 0.3832 - val_acc: 0.8296\n",
            "Epoch 273/300\n",
            " - 5s - loss: 0.3963 - acc: 0.8280 - val_loss: 0.3830 - val_acc: 0.8296\n",
            "Epoch 274/300\n",
            " - 5s - loss: 0.3885 - acc: 0.8276 - val_loss: 0.3829 - val_acc: 0.8296\n",
            "Epoch 275/300\n",
            " - 5s - loss: 0.3957 - acc: 0.8269 - val_loss: 0.3827 - val_acc: 0.8304\n",
            "Epoch 276/300\n",
            " - 5s - loss: 0.3872 - acc: 0.8355 - val_loss: 0.3826 - val_acc: 0.8304\n",
            "Epoch 277/300\n",
            " - 5s - loss: 0.3912 - acc: 0.8304 - val_loss: 0.3825 - val_acc: 0.8304\n",
            "Epoch 278/300\n",
            " - 5s - loss: 0.3971 - acc: 0.8260 - val_loss: 0.3824 - val_acc: 0.8311\n",
            "Epoch 279/300\n",
            " - 5s - loss: 0.3918 - acc: 0.8239 - val_loss: 0.3822 - val_acc: 0.8311\n",
            "Epoch 280/300\n",
            " - 5s - loss: 0.3944 - acc: 0.8265 - val_loss: 0.3821 - val_acc: 0.8311\n",
            "Model saved for epoch  279 10\n",
            "Epoch 281/300\n",
            " - 5s - loss: 0.3890 - acc: 0.8291 - val_loss: 0.3820 - val_acc: 0.8311\n",
            "Epoch 282/300\n",
            " - 5s - loss: 0.3876 - acc: 0.8293 - val_loss: 0.3818 - val_acc: 0.8311\n",
            "Epoch 283/300\n",
            " - 5s - loss: 0.3913 - acc: 0.8265 - val_loss: 0.3817 - val_acc: 0.8311\n",
            "Epoch 284/300\n",
            " - 5s - loss: 0.3947 - acc: 0.8245 - val_loss: 0.3815 - val_acc: 0.8311\n",
            "Epoch 285/300\n",
            " - 5s - loss: 0.3942 - acc: 0.8225 - val_loss: 0.3814 - val_acc: 0.8311\n",
            "Epoch 286/300\n",
            " - 5s - loss: 0.3944 - acc: 0.8241 - val_loss: 0.3813 - val_acc: 0.8311\n",
            "Epoch 287/300\n",
            " - 5s - loss: 0.3950 - acc: 0.8208 - val_loss: 0.3812 - val_acc: 0.8311\n",
            "Epoch 288/300\n",
            " - 5s - loss: 0.3875 - acc: 0.8269 - val_loss: 0.3810 - val_acc: 0.8311\n",
            "Epoch 289/300\n",
            " - 5s - loss: 0.3899 - acc: 0.8311 - val_loss: 0.3809 - val_acc: 0.8311\n",
            "Epoch 290/300\n",
            " - 5s - loss: 0.3865 - acc: 0.8355 - val_loss: 0.3808 - val_acc: 0.8311\n",
            "Model saved for epoch  289 10\n",
            "Epoch 291/300\n",
            " - 5s - loss: 0.3843 - acc: 0.8309 - val_loss: 0.3806 - val_acc: 0.8311\n",
            "Epoch 292/300\n",
            " - 5s - loss: 0.3936 - acc: 0.8258 - val_loss: 0.3805 - val_acc: 0.8311\n",
            "Epoch 293/300\n",
            " - 5s - loss: 0.3945 - acc: 0.8256 - val_loss: 0.3804 - val_acc: 0.8311\n",
            "Epoch 294/300\n",
            " - 5s - loss: 0.3925 - acc: 0.8267 - val_loss: 0.3802 - val_acc: 0.8311\n",
            "Epoch 295/300\n",
            " - 5s - loss: 0.3912 - acc: 0.8291 - val_loss: 0.3801 - val_acc: 0.8311\n",
            "Epoch 296/300\n",
            " - 5s - loss: 0.3833 - acc: 0.8295 - val_loss: 0.3800 - val_acc: 0.8319\n",
            "Epoch 297/300\n",
            " - 5s - loss: 0.3949 - acc: 0.8247 - val_loss: 0.3798 - val_acc: 0.8326\n",
            "Epoch 298/300\n",
            " - 5s - loss: 0.3942 - acc: 0.8230 - val_loss: 0.3797 - val_acc: 0.8326\n",
            "Epoch 299/300\n",
            " - 5s - loss: 0.3868 - acc: 0.8297 - val_loss: 0.3796 - val_acc: 0.8326\n",
            "Epoch 300/300\n",
            " - 5s - loss: 0.3913 - acc: 0.8354 - val_loss: 0.3795 - val_acc: 0.8333\n",
            "Model saved for epoch  299 10\n",
            "Testing classifier...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.76      0.79       552\n",
            "           1       0.78      0.84      0.81       552\n",
            "\n",
            "    accuracy                           0.80      1104\n",
            "   macro avg       0.80      0.80      0.80      1104\n",
            "weighted avg       0.80      0.80      0.80      1104\n",
            "\n",
            "Experiment completed.\n",
            "Session ended.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAXP13oENNqW",
        "colab_type": "text"
      },
      "source": [
        "# Generate Explainers\n",
        "We generate 3 types of explanations for the trained model:\n",
        "- LIME\n",
        "- Prototypes\n",
        "- Saliency maps\n",
        "\n",
        "The original model used for the study is `/model/model_e299.h5`.  To use a different trained model, change the value of `load_location` in the dictionary `model_params`. \n",
        "\n",
        "Outputted explanations are stored in `/output/`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MRsTJESNP7F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "1d6f1ede-77e0-4152-8bbb-29426a4e01ea"
      },
      "source": [
        "num_epochs = 300\n",
        "batch_size = 256\n",
        "\n",
        "dl_params = {\n",
        "        'labels':           ['sun', 'moon'],\n",
        "        'label_type':       'int',\n",
        "        'presorted':        True,\n",
        "        'file_locs':        [\"./data/kuzushiji-49/0\", \"./data/kuzushiji-49/33\"],\n",
        "        'file_exten':       '.png',\n",
        "        'set_ratio':        [0.8, 0.2],\n",
        "        'batch_size':       batch_size,\n",
        "        'target_size':      (28,28),\n",
        "        'balanced':         True,\n",
        "        'grayscale':        True,\n",
        "        'superspeedmode':   False                #   trades off memory efficiency for less computation (USE AT YOUR OWN RISK)\n",
        "}\n",
        "\n",
        "model_params = {\n",
        "    'output_dim':           1,\n",
        "    'activation':           'relu',\n",
        "    'load_location':        './model/model_e299.h5'\n",
        "}\n",
        "\n",
        "#   dictionary containing each explainer as key and list of list of text, with each\n",
        "#   list within a list contains text for each explanation with an explainer\n",
        "\n",
        "text_files = ['lime.txt', 'heatmap.txt', 'prototypes.txt']\n",
        "text_dict = {}\n",
        "for file in text_files:\n",
        "    text_dict = experiment.populate_text_dict(file, text_dict)\n",
        "\n",
        "print(text_dict['prototypes'])\n",
        "\n",
        "explain_params = {\n",
        "            'border' :          (0, 0),\n",
        "            'num_images':       3,\n",
        "            'font_file' :       'Arial.ttf',\n",
        "            'text_size' :       30,\n",
        "            'text_dict':        text_dict,\n",
        "            'imagenet':         False\n",
        "            }\n",
        "    \n",
        "#   create save directory\n",
        "save_dir = \"./output/\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[\"WALTER : I think the images on the left represent the sun.  The smaller images on the right are the 3 most similar images that I've seen before, when compared to each of these images.  The ground-truth labels of these images are below each one.\", ' ', ' ', \"WALTER : OK, I just checked the labels for the images on the left.  I'm correct :)  They all represent the sun!\"], [\"WALTER : I think the images on the left represent the moon.  The smaller images on the right are the 3 most similar images that I've seen before, when compared to each of these images.  The ground-truth labels of these images are below each one.\", ' ', ' ', \"WALTER : OK, I just checked the labels for the images on the left.  I'm correct :)  They all represent the moon!\"], [\"WALTER : I think the images on the left represent the moon.  The smaller images on the right are the 3 most similar images that I've seen before, when compared to each of these images.  The ground-truth labels of these images are below each one.\", ' ', ' ', \"WALTER : OK, I just checked the labels for the images on the left.  I'm wrong :(  They actually all represent the sun!\"], [\"WALTER : I think the images on the left represent the sun.  The smaller images on the right are the 3 most similar images that I've seen before, when compared to each of these images.  The ground-truth labels of these images are below each one.\", ' ', ' ', \"WALTER : OK, I just checked the labels for the images on the left.  I'm wrong :(  They actually all represent the moon!\"]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03uE7yvyPc-A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "outputId": "38d7d044-9499-449b-8e90-c8f65043fe1e"
      },
      "source": [
        "experiment.experiment(dl_params, model_params, explain_params, save_dir)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "Loading data from ./data/kuzushiji-49/0 ...\n",
            "Getting samples for class 0...\n",
            "There are 2715 training, 678validation, 552 test samples.\n",
            "Loading data from ./data/kuzushiji-49/33 ...\n",
            "Getting samples for class 1...\n",
            "There are 2715 training, 678validation, 552 test samples.\n",
            "There are 5430 training samples and 22 training batches.\n",
            "There are 1356 validation samples and 6 validation batches.\n",
            "There are 1104 test samples and 5 test batches.\n",
            "X_train.shape:  (5430, 28, 28, 1)\n",
            "Converting from grayscale to RGB...\n",
            "Flattening data...\n",
            "Finding prototypes for only label 0\n",
            "Explaining...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Plotting prototypes...\n",
            "Number of prototypes:  (5, 28, 28, 3)\n",
            "Flattening data...\n",
            "Finding prototypes for only label 1\n",
            "Explaining...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Plotting prototypes...\n",
            "Number of prototypes:  (5, 28, 28, 3)\n",
            "Loading pre-existing classifier...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1112\u001b[0m             subfeed_t = self.graph.as_graph_element(\n\u001b[0;32m-> 1113\u001b[0;31m                 subfeed, allow_tensor=True, allow_operation=False)\n\u001b[0m\u001b[1;32m   1114\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3795\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3796\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3874\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3875\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3876\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"Placeholder_28:0\", shape=(5, 5, 3, 3), dtype=float32) is not an element of this graph.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-072b648443b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplain_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/experiment.py\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(dl_params, model_params, explain_params, save_dir)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;31m#   add this line to prevent some Keras serializer error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'GlorotUniform'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mglorot_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'load_location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;31m#   run prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(f, custom_objects, compile)\u001b[0m\n\u001b[1;32m    285\u001b[0m                              ' elements.')\n\u001b[1;32m    286\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2468\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2470\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1114\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             raise TypeError(\n\u001b[0;32m-> 1116\u001b[0;31m                 'Cannot interpret feed_dict key as Tensor: ' + e.args[0])\n\u001b[0m\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder_28:0\", shape=(5, 5, 3, 3), dtype=float32) is not an element of this graph."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z0eubjRhDFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}